{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b0b775c8-87e2-4603-8862-1c302fe3b97c",
   "metadata": {},
   "source": [
    "---\n",
    "title: Predicting Net Rating of NBA Players\n",
    "subtitle: Project Report for STAT 303-2 Winter 2025\n",
    "author: Sky Park\n",
    "date: March 18, 2025\n",
    "abstract: This report analyzes the relationship between various basketball player statistics and their net_rating, focusing on identifying the most influential predictors. Through regression analysis, I found that rebounds (reb), assists (ast), and player usage percentage (usg_pct) significantly affect net_rating, with rebounds and assists positively influencing it, while higher usage percentages detract from net_rating. Points (pts) and true shooting percentage (ts_pct) showed weaker or statistically insignificant effects. Additionally, the interaction between ts_pct and usg_pct demonstrated a meaningful contribution to net_rating. The model explains 19.1% of the variation in net_rating, suggesting that the selected predictors offer valuable insights into player performance. Based on these findings, I recommend that teams focus on improving rebounds, assists, and managing player usage to optimize net_rating. Further analysis could include exploring additional predictors or improving the modelâ€™s explanatory power by considering different player metrics.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d1a47-c6df-4996-beac-078b07c4268c",
   "metadata": {},
   "source": [
    "## 1) Inspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adfbc85-ddbf-44ab-a0e5-04d6c0bce5b2",
   "metadata": {},
   "source": [
    "I've always been a huge NBA fan, and I'm very interested in player's stats and averages. I think the dataset is worth exploring in order to see how net rating is related to the overall statistics of a player. Some player in the NBA can put up impressive statlines, but do not necessarily contribute to winning basketball games. This project will explore which basketball statistics actually contribute to winning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52cf72c-1e4b-4dd8-9a38-75a6bd26a2d5",
   "metadata": {},
   "source": [
    "## 2) Stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73900f92-2a74-4c1c-8ef1-b16eb8cce92a",
   "metadata": {},
   "source": [
    "General Managers and coaching staff of NBA teams would be interested in hearing the results of this project. This project would benefit them by showing how their player's statistics contribute to winning on the court."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e2949-b0d7-4631-a738-0b6bba1fe7a5",
   "metadata": {},
   "source": [
    "## 3) Task and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d0f458-2caa-4a78-b9d7-0515798076b3",
   "metadata": {},
   "source": [
    "This project will be a regression problem since net_rating is a continuous variable.\n",
    "\n",
    "My evaluation metric will be MAE. I don't need to penalize bigger errors with RMSE, so MAE will do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3ed81-75ae-483e-b3dc-f28ae9cd3ca3",
   "metadata": {},
   "source": [
    "## 4) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a946b-ff9f-487c-82d6-2fbe3d1d3785",
   "metadata": {},
   "source": [
    "My dataset contains all the NBA players from the 1996 to 2021 seasons and all their descriptive information (height, weight, college) and statistics (points, rebounds, assists, shooting percentages).\n",
    "\n",
    "Link: https://www.kaggle.com/datasets/justinas/nba-players-data?resource=download\n",
    "\n",
    "There are 12844 observations and 22 columns. There are 8 categorical variables and 14 numeric variables.\n",
    "\n",
    "Each observation is an NBA player's season. Since it is data from 1996 to 2021, players that played multiple seasons in that time have an observation for each season. The variables represent their statistics from that season. My response variable, 'net_rating', is the teams point differential per 100 possessions when a player is on/off the court. 'ts_pct' is True Shooting Percentage, 'usg_pct' is usage percentage, 'pts' is average points, 'reb' is average rebounds, 'ast' is average assists, 'ast_pct' is assist percentage, 'oreb_pct' is offensive rebound percentage, and 'dreb_pct' is defensive rebound percentage.\n",
    "\n",
    "The response variable is the 'net_rating' column, and the predictor variables are usg_pct, pts, reb, ast, ts_pct, ast_pct, oreb_pct, dreb_pct, gp, and age.\n",
    "\n",
    "CLEANING: I excluded observations from the dataset where gp was less than 20. This is because if players play less than 20 games in a season, their statistical averages might skew/misrepresent due to lack of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e563fa-ee97-4c50-b9d2-2322b87486d4",
   "metadata": {},
   "source": [
    "## 5) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee2eea-db35-44dd-a60d-c0841e009856",
   "metadata": {},
   "source": [
    "For my first model, I used 'ts_pct' as my predictor because it had the highest correlation with net_rating (0.36). The training MAE was 4.67, and the test MAE was also 4.67.\n",
    "\n",
    "Here is a table showing the rest of the predictors being added along with the test and training RMSE, and test and training R^2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e392bfac-dd68-483d-917b-a0a1319e1331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance with each set of predictors:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictors</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Train R^2</th>\n",
       "      <th>Test R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ts_pct</td>\n",
       "      <td>4.670336</td>\n",
       "      <td>4.671505</td>\n",
       "      <td>0.135979</td>\n",
       "      <td>0.139392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ts_pct, pts</td>\n",
       "      <td>4.616341</td>\n",
       "      <td>4.612677</td>\n",
       "      <td>0.156190</td>\n",
       "      <td>0.163970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ts_pct, pts, reb</td>\n",
       "      <td>4.607351</td>\n",
       "      <td>4.604622</td>\n",
       "      <td>0.159138</td>\n",
       "      <td>0.166505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ts_pct, pts, reb, ast</td>\n",
       "      <td>4.561700</td>\n",
       "      <td>4.556252</td>\n",
       "      <td>0.172178</td>\n",
       "      <td>0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ts_pct, pts, reb, ast</td>\n",
       "      <td>4.561700</td>\n",
       "      <td>4.556252</td>\n",
       "      <td>0.172178</td>\n",
       "      <td>0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ts_pct, pts, reb, ast, ast_pct</td>\n",
       "      <td>4.557704</td>\n",
       "      <td>4.548110</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.187443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ts_pct, pts, reb, ast, ast_pct, oreb_pct</td>\n",
       "      <td>4.557575</td>\n",
       "      <td>4.547300</td>\n",
       "      <td>0.175661</td>\n",
       "      <td>0.187640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ts_pct, pts, reb, ast, ast_pct, oreb_pct, dreb...</td>\n",
       "      <td>4.551968</td>\n",
       "      <td>4.528890</td>\n",
       "      <td>0.178205</td>\n",
       "      <td>0.193172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ts_pct, pts, reb, ast, ast_pct, oreb_pct, dreb...</td>\n",
       "      <td>4.468096</td>\n",
       "      <td>4.463113</td>\n",
       "      <td>0.206976</td>\n",
       "      <td>0.211481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ts_pct, pts, reb, ast, ast_pct, oreb_pct, dreb...</td>\n",
       "      <td>4.423564</td>\n",
       "      <td>4.426429</td>\n",
       "      <td>0.222523</td>\n",
       "      <td>0.226889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ts_pct, pts, reb, ast, ast_pct, oreb_pct, dreb...</td>\n",
       "      <td>4.419731</td>\n",
       "      <td>4.427293</td>\n",
       "      <td>0.223127</td>\n",
       "      <td>0.226353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Predictors  Train MAE  Test MAE  \\\n",
       "0                                              ts_pct   4.670336  4.671505   \n",
       "1                                         ts_pct, pts   4.616341  4.612677   \n",
       "2                                    ts_pct, pts, reb   4.607351  4.604622   \n",
       "3                               ts_pct, pts, reb, ast   4.561700  4.556252   \n",
       "4                               ts_pct, pts, reb, ast   4.561700  4.556252   \n",
       "5                      ts_pct, pts, reb, ast, ast_pct   4.557704  4.548110   \n",
       "6            ts_pct, pts, reb, ast, ast_pct, oreb_pct   4.557575  4.547300   \n",
       "7   ts_pct, pts, reb, ast, ast_pct, oreb_pct, dreb...   4.551968  4.528890   \n",
       "8   ts_pct, pts, reb, ast, ast_pct, oreb_pct, dreb...   4.468096  4.463113   \n",
       "9   ts_pct, pts, reb, ast, ast_pct, oreb_pct, dreb...   4.423564  4.426429   \n",
       "10  ts_pct, pts, reb, ast, ast_pct, oreb_pct, dreb...   4.419731  4.427293   \n",
       "\n",
       "    Train R^2  Test R^2  \n",
       "0    0.135979  0.139392  \n",
       "1    0.156190  0.163970  \n",
       "2    0.159138  0.166505  \n",
       "3    0.172178  0.184453  \n",
       "4    0.172178  0.184453  \n",
       "5    0.175600  0.187443  \n",
       "6    0.175661  0.187640  \n",
       "7    0.178205  0.193172  \n",
       "8    0.206976  0.211481  \n",
       "9    0.222523  0.226889  \n",
       "10   0.223127  0.226353  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = pd.read_csv('all_seasons.csv')\n",
    "\n",
    "data = data[data['gp'] > 20]\n",
    "\n",
    "predictors = ['pts', 'reb', 'ast', 'ts_pct', 'ast_pct', 'oreb_pct', 'dreb_pct', 'age', 'gp', 'usg_pct']\n",
    "results = []\n",
    "\n",
    "X = data[['ts_pct']]  # Chosen as the first predictor because it has the highest correlation with net_rating\n",
    "y = data['net_rating']\n",
    "\n",
    "# Split into train and test 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MAE and R^2\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Df with results\n",
    "results.append({\n",
    "    'Predictors': 'ts_pct',\n",
    "    'Train MAE': train_mae,\n",
    "    'Test MAE': test_mae,\n",
    "    'Train R^2': r2_train,\n",
    "    'Test R^2': r2_test\n",
    "})\n",
    "\n",
    "X = X.copy()\n",
    "\n",
    "\n",
    "for predictor in predictors[0:]:\n",
    "\n",
    "    if predictor in data.columns:\n",
    "        X[predictor] = data[predictor]\n",
    "    else:\n",
    "        print(f\"Warning: '{predictor}' not found in the DataFrame columns. Skipping it.\")\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_const = sm.add_constant(X_train)\n",
    "    X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "    model = sm.OLS(y_train, X_train_const).fit()\n",
    "\n",
    "    y_train_pred = model.predict(X_train_const)\n",
    "    y_test_pred = model.predict(X_test_const)\n",
    "\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    results.append({\n",
    "        'Predictors': ', '.join(X.columns),\n",
    "        'Train MAE': train_mae,\n",
    "        'Test MAE': test_mae,\n",
    "        'Train R^2': r2_train,\n",
    "        'Test R^2': r2_test\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nPerformance with each set of predictors:\\n\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf640351-54a7-40f8-872a-6b1f60c3af50",
   "metadata": {},
   "source": [
    "After creating a model with my non-linear terms, I found that no predictors had a coef of 0. Here are the five most important and five least important terms from my trained and tuned polynomial model, regularized using Lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8e62b02a-b1f2-4214-b0d9-3bc013ebed88",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Most Important Predictors:\n",
      "         Predictor  Coefficient\n",
      "31     reb ast_pct   -12.066458\n",
      "9          usg_pct    -8.158342\n",
      "1              pts    -8.003121\n",
      "43     ast usg_pct     6.078292\n",
      "19  ts_pct usg_pct     5.464256\n",
      "\n",
      "Top 5 Least Important Predictors:\n",
      "           Predictor  Coefficient\n",
      "62              gp^2     0.198761\n",
      "27            pts gp     0.137600\n",
      "45  ast_pct oreb_pct    -0.111271\n",
      "22           pts ast     0.061311\n",
      "2                reb    -0.036364\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LogisticRegressionCV\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train) \n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_poly)\n",
    "X_train_poly_scaled = scaler.transform(X_train_poly)\n",
    "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "alphas = 10**np.linspace(10,-2,200)*0.5\n",
    "\n",
    "rcv = RidgeCV(alphas=alphas, cv=5)\n",
    "\n",
    "rcv.fit(X_train_poly_scaled, y_train)\n",
    "\n",
    "y_pred = rcv.predict(X_test_poly_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "coefficients = rcv.coef_\n",
    "\n",
    "feature_names = poly.get_feature_names_out(X_train.columns)\n",
    "coef_df = pd.DataFrame({\n",
    "    'Predictor': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "\n",
    "coef_df_sorted = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Predictors:\")\n",
    "print(coef_df_sorted.head(5)[['Predictor', 'Coefficient']])\n",
    "\n",
    "print(\"\\nTop 5 Least Important Predictors:\")\n",
    "print(coef_df_sorted.tail(5)[['Predictor', 'Coefficient']])\n",
    "\n",
    "zero_coef_df = coef_df_sorted[coef_df_sorted['Coefficient'] == 0]\n",
    "if not zero_coef_df.empty:\n",
    "    print(\"\\nTerms with Zero Coefficients:\")\n",
    "    print(zero_coef_df[['Predictor', 'Coefficient']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57daf0a9-79a7-4858-9e78-1f2e99ba18b4",
   "metadata": {},
   "source": [
    "After cross-validating, I found the best hyperparameter to be 1.95, and the Test MAE of my trained and tuned model is 4.25. The best CV score is 0.27.\n",
    "\n",
    "Looking at my list of most important predictors, usg_pct seems to be very informative. The original predictor of usg_pct is in the list, and it is also included in two interaction terms, ast * usg_pct and ts_pct * usg_pct.\n",
    "\n",
    "From looking at my performance table where I add one predictor to the model each time, pts is very influential in reducing the MAE, reducing the Training and Test MAE by ~0.6. Another predictor that seems to have a large impact is age. When age is added into the model, Training MAE reduces by ~0.8, and Test MAE reduces by ~0.6. These two predictors reduce MAE by significantly more than the other predictors.\n",
    "\n",
    "From looking at my Least Important Predictors table, gp seems to not be informative to the model. The transformation term gp^2 and the interaction term pts * gp are both in this list. Looking at my performance table, the variables oreb_pct and dreb_pct also seem to be low-impact predictors because both of them negligibly change the Training or Test MAE (<0.01).\n",
    "\n",
    "There seems to be non-linearities in the relationship between net_rating and the predictors. This can be seen because the Test MAE of the polynomial model is 4.25, which is lower than the Test MAE of the earlier model (4.42). This means that the non-linear terms in the new model fit the relationship better, reducing error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0092ba-1cc3-4e07-b56b-0bbe2005a40e",
   "metadata": {},
   "source": [
    "## 6) Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200fe74d-a41e-4425-9140-8dbdb6024462",
   "metadata": {},
   "source": [
    "My original predictors for this model are reb, ast_pct, usg_pct, pts, ast, and ts_pct, and my interaction terms are reb * ast_pct, ast * usg_pct, and ts_pct * usg_pct. I got these terms from my top 5 most informative list in my table in my prediction section.\n",
    "\n",
    "Here is a summary of the model that includes these influential predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "44a887dd-532e-443d-ab41-d2edcc5a20fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>net_rating</td>    <th>  R-squared:         </th> <td>   0.191</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.190</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   278.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 18 Mar 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:33:09</td>     <th>  Log-Likelihood:    </th> <td> -33628.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10627</td>      <th>  AIC:               </th> <td>6.728e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 10617</td>      <th>  BIC:               </th> <td>6.735e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>   -1.0456</td> <td>    0.056</td> <td>  -18.807</td> <td> 0.000</td> <td>   -1.155</td> <td>   -0.937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(reb)</th>              <td>    0.4826</td> <td>    0.127</td> <td>    3.809</td> <td> 0.000</td> <td>    0.234</td> <td>    0.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(ast_pct)</th>          <td>   -0.4689</td> <td>    0.165</td> <td>   -2.848</td> <td> 0.004</td> <td>   -0.792</td> <td>   -0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(usg_pct)</th>          <td>   -6.1785</td> <td>    0.532</td> <td>  -11.616</td> <td> 0.000</td> <td>   -7.221</td> <td>   -5.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(pts)</th>              <td>    0.3528</td> <td>    0.183</td> <td>    1.929</td> <td> 0.054</td> <td>   -0.006</td> <td>    0.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(ast)</th>              <td>    1.6525</td> <td>    0.301</td> <td>    5.485</td> <td> 0.000</td> <td>    1.062</td> <td>    2.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(ts_pct)</th>           <td>   -0.2160</td> <td>    0.211</td> <td>   -1.025</td> <td> 0.305</td> <td>   -0.629</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(reb * ast_pct)</th>    <td>   -0.0311</td> <td>    0.170</td> <td>   -0.182</td> <td> 0.855</td> <td>   -0.365</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(ast * usg_pct)</th>    <td>   -0.2358</td> <td>    0.294</td> <td>   -0.801</td> <td> 0.423</td> <td>   -0.813</td> <td>    0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(ts_pct * usg_pct)</th> <td>    6.2596</td> <td>    0.625</td> <td>   10.015</td> <td> 0.000</td> <td>    5.034</td> <td>    7.485</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>122.102</td> <th>  Durbin-Watson:     </th> <td>   1.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 162.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.164</td>  <th>  Prob(JB):          </th> <td>4.23e-36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.510</td>  <th>  Cond. No.          </th> <td>    34.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}            &   net\\_rating    & \\textbf{  R-squared:         } &     0.191   \\\\\n",
       "\\textbf{Model:}                    &       OLS        & \\textbf{  Adj. R-squared:    } &     0.190   \\\\\n",
       "\\textbf{Method:}                   &  Least Squares   & \\textbf{  F-statistic:       } &     278.8   \\\\\n",
       "\\textbf{Date:}                     & Tue, 18 Mar 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                     &     21:33:09     & \\textbf{  Log-Likelihood:    } &   -33628.   \\\\\n",
       "\\textbf{No. Observations:}         &       10627      & \\textbf{  AIC:               } & 6.728e+04   \\\\\n",
       "\\textbf{Df Residuals:}             &       10617      & \\textbf{  BIC:               } & 6.735e+04   \\\\\n",
       "\\textbf{Df Model:}                 &           9      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}          &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                 &      -1.0456  &        0.056     &   -18.807  &         0.000        &       -1.155    &       -0.937     \\\\\n",
       "\\textbf{scale(reb)}                &       0.4826  &        0.127     &     3.809  &         0.000        &        0.234    &        0.731     \\\\\n",
       "\\textbf{scale(ast\\_pct)}           &      -0.4689  &        0.165     &    -2.848  &         0.004        &       -0.792    &       -0.146     \\\\\n",
       "\\textbf{scale(usg\\_pct)}           &      -6.1785  &        0.532     &   -11.616  &         0.000        &       -7.221    &       -5.136     \\\\\n",
       "\\textbf{scale(pts)}                &       0.3528  &        0.183     &     1.929  &         0.054        &       -0.006    &        0.711     \\\\\n",
       "\\textbf{scale(ast)}                &       1.6525  &        0.301     &     5.485  &         0.000        &        1.062    &        2.243     \\\\\n",
       "\\textbf{scale(ts\\_pct)}            &      -0.2160  &        0.211     &    -1.025  &         0.305        &       -0.629    &        0.197     \\\\\n",
       "\\textbf{scale(reb * ast\\_pct)}     &      -0.0311  &        0.170     &    -0.182  &         0.855        &       -0.365    &        0.303     \\\\\n",
       "\\textbf{scale(ast * usg\\_pct)}     &      -0.2358  &        0.294     &    -0.801  &         0.423        &       -0.813    &        0.341     \\\\\n",
       "\\textbf{scale(ts\\_pct * usg\\_pct)} &       6.2596  &        0.625     &    10.015  &         0.000        &        5.034    &        7.485     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 122.102 & \\textbf{  Durbin-Watson:     } &    1.932  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  162.902  \\\\\n",
       "\\textbf{Skew:}          &  -0.164 & \\textbf{  Prob(JB):          } & 4.23e-36  \\\\\n",
       "\\textbf{Kurtosis:}      &   3.510 & \\textbf{  Cond. No.          } &     34.7  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             net_rating   R-squared:                       0.191\n",
       "Model:                            OLS   Adj. R-squared:                  0.190\n",
       "Method:                 Least Squares   F-statistic:                     278.8\n",
       "Date:                Tue, 18 Mar 2025   Prob (F-statistic):               0.00\n",
       "Time:                        21:33:09   Log-Likelihood:                -33628.\n",
       "No. Observations:               10627   AIC:                         6.728e+04\n",
       "Df Residuals:                   10617   BIC:                         6.735e+04\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                  -1.0456      0.056    -18.807      0.000      -1.155      -0.937\n",
       "scale(reb)                  0.4826      0.127      3.809      0.000       0.234       0.731\n",
       "scale(ast_pct)             -0.4689      0.165     -2.848      0.004      -0.792      -0.146\n",
       "scale(usg_pct)             -6.1785      0.532    -11.616      0.000      -7.221      -5.136\n",
       "scale(pts)                  0.3528      0.183      1.929      0.054      -0.006       0.711\n",
       "scale(ast)                  1.6525      0.301      5.485      0.000       1.062       2.243\n",
       "scale(ts_pct)              -0.2160      0.211     -1.025      0.305      -0.629       0.197\n",
       "scale(reb * ast_pct)       -0.0311      0.170     -0.182      0.855      -0.365       0.303\n",
       "scale(ast * usg_pct)       -0.2358      0.294     -0.801      0.423      -0.813       0.341\n",
       "scale(ts_pct * usg_pct)     6.2596      0.625     10.015      0.000       5.034       7.485\n",
       "==============================================================================\n",
       "Omnibus:                      122.102   Durbin-Watson:                   1.932\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              162.902\n",
       "Skew:                          -0.164   Prob(JB):                     4.23e-36\n",
       "Kurtosis:                       3.510   Cond. No.                         34.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(formula= 'net_rating ~ scale(reb) + scale(ast_pct) + scale(usg_pct) + scale(pts) + scale(ast) + scale(ts_pct) + scale(reb*ast_pct) + scale(ast*usg_pct) + scale(ts_pct*usg_pct)', data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8d7f3-b84c-4b32-a323-5a57627e332e",
   "metadata": {},
   "source": [
    "Now, I will discuss the effect of each predictor on the response, net_rating, using the coefs from the summary:\n",
    "\n",
    "- reb (0.4826) - For each additional rebound a player records, net_rating goes up by 0.1966.  \n",
    "- ast_pct\t(-0.4689) - For each 1% increase in a player's ast_pct, net_rating goes down by 0.4689.  \n",
    "- usg_pct\t(-6.1785) - For each 1% increase in a player's usg_pct, net_rating goes down by 6.1785.  \n",
    "- pts\t(0.3528) - For each additional point a player records, net_rating goes up by 0.3528.  \n",
    "- ast\t(1.6525) - For each additional assist a player records, net_rating goes up by 1.6525.  \n",
    "- ts_pct (-0.2160) - For each 1% increase in a player's ts_pct, net_rating goes down by 0.2160.  \n",
    "- reb * ast_pct (-0.0311) - For each additional rebound a player records, the effect of their ast_pct on net_rating decreases by 0.0311.\n",
    "- ast * usg_pct (-0.2358) - For each additional assist a player records, the effect of their usg_pct on net_rating decreases by 0.2358.\n",
    "- ts_pct * usg_pct (6.2596) - For each 1% increase in usg_pct, the effect of ts_pct on net_rating increases by 6.2596.\n",
    "\n",
    "Now, I will discuss the the reliability of the effect of each predictor using the p values from the summary:\n",
    "\n",
    "- reb (0.000) â€“ The p-value is highly significant, indicating that reb has a reliable and strong effect on the target variable. This suggests that reb is an influential predictor in the model.\n",
    "- ast_pct (0.004) â€“ With a p-value well below 0.05, ast_pct is statistically significant, demonstrating a reliable effect on the target variable. This means that ast_pct contributes meaningfully to the model's predictive power.\n",
    "- usg_pct (0.000) â€“ The p-value is extremely low, indicating a highly reliable and significant effect. This confirms that usg_pct is an important and consistent predictor.\n",
    "- pts (0.054) â€“ The p-value is above the threshold of 0.05, which means that the effect of pts on the model is stastically insignificant.\n",
    "- ast (0.000) â€“ The p-value is extremely low, confirming a highly significant and reliable effect. This indicates that ast is a strong and consistent predictor.\n",
    "- ts_pct (0.305) â€“ The p-value is much higher than 0.05, indicating no reliable effect. This suggests that ts_pct does not significantly influence the target variable and may not be a meaningful predictor in the model.\n",
    "- reb * ast_pct (0.855) â€“ With a very high p-value, this interaction term is not statistically significant, indicating no reliable effect. The combination of reb and ast_pct does not meaningfully influence the target variable.\n",
    "- ast * usg_pct (0.423) â€“ The p-value is well above 0.05, showing no reliable effect. This indicates that the interaction between ast and usg_pct does not significantly contribute to the model.\n",
    "- ts_pct * usg_pct (0.000) â€“ The p-value is extremely low, making this interaction term highly significant and reliable. This suggests that the combined effect of ts_pct and usg_pct has a meaningful and consistent influence on the target variable.\n",
    "\n",
    "\n",
    "The overall model has a R-squared value of 0.191, which means that 19.1% of the variation in net_rating can be explained by the predictors included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835755f2-7ef2-4127-8219-35dd67ee2e54",
   "metadata": {},
   "source": [
    "## 7) Recommendation to Stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d29cce-ca95-40c1-96b1-7b88f52055d3",
   "metadata": {},
   "source": [
    "Here are the main action items for NBA coaching staff or GMS to focus on based on my analysis:\n",
    "\n",
    "- Focus on rebounds (reb): Since rebounds have a strong and reliable effect on net_rating, coaches should prioritize players who can consistently record more rebounds to improve team performance.\n",
    "- Manage player usage (usg_pct): The negative relationship between usg_pct and net_rating suggests that players with a high usage percentage may lower the team's overall effectiveness. NBA coaches may want to adjust how often high-usage players are involved in plays to avoid diminishing returns on net_rating.\n",
    "- Encourage assists (ast): Since assists have a significant positive effect on net_rating, focusing on improving playmaking abilities and encouraging more assists could improve team performance.\n",
    "- Minimize reliance on TS% (ts_pct): Given that TS% has no significant effect on net_rating (with a high p-value), coaches may want to reassess its emphasis as a key performance indicator, focusing more on other factors like assists and rebounds.\n",
    "- Consider interaction between ts_pct and usg_pct: The significant interaction between ts_pct and usg_pct suggests that players with higher usage may benefit from an improved TS%, and this combination should be considered when managing players.\n",
    "\n",
    "Here are some limitations of my analysis:\n",
    "- Limited explanatory power: The R-squared value of 0.191 indicates that only 19.1% of the variation in net_rating can be explained by the model. This means there are other important factors affecting net_rating that aren't captured in this analysis.\n",
    "- Insignificant predictors: Several predictors, such as pts, ts_pct, and the interaction terms (reb * ast_pct, ast * usg_pct), do not show a significant effect on net_rating (with p-values above 0.05). This indicates that the model may be overlooking important variables or interactions that could better explain the target variable.\n",
    "- Potential model misspecification: The model may be missing key predictors or interactions that could improve the predictive power. Additionally, some of the included variables might not fully represent the real-world dynamics of player performance.\n",
    "- Contextual factors missing: The analysis does not account for contextual factors such as game situation, team strategy, or player roles that could influence the relationship between the predictors and net_rating.\n",
    "\n",
    "In order to overcome these limitations, I would conduct further analysis with a wider range of variables, such as minutes per game, defensive metrics, or PER (player efficiency ratings). I would also try to implement more non-linear relationships or interaction terms in order to capture more the variance of net_ratings with my model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38e16b-8b71-4c52-8769-c22d6486f3b6",
   "metadata": {},
   "source": [
    "## 8) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90b2f6-2124-400a-bbc9-660942193dca",
   "metadata": {},
   "source": [
    "In this analysis, I examined the relationship between various player statistics and net_rating, using both prediction and inference methods. I found that rebounds (reb), assists (ast), and player usage percentage (usg_pct) have significant and reliable effects on net_rating. Specifically, rebounds and assists contribute positively to a playerâ€™s net_rating, while higher usage percentages negatively impact it. Points (pts) and true shooting percentage (ts_pct) showed weaker or insignificant effects, and the interaction between ts_pct and usg_pct proved meaningful. The model explains 19.1% of the variation in net_rating, indicating that these predictors provide valuable insights into player performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
